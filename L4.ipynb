{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtiK_knaYQ84"
      },
      "source": [
        "# CSC 480-F25 Lab 4: Agentic Monte Carlo Search\n",
        "### Authors:\n",
        "***Grady Schneider***\n",
        "\n",
        "California Polytechnic State University, San Luis Obispo;\n",
        "Computer Science & Software Engineering Department\n",
        "\n",
        "### Overview\n",
        "This lab focuses on:\n",
        "*   Understanding and implementing Monte Carlo Search for a complex puzzle (NYT Spelling Bee).\n",
        "*   Improving the random simulation (rollout) process by designing a smarter heuristic.\n",
        "*   Decomposing the Monte Carlo Search algorithm into a multi-agent system using AutoGen.\n",
        "*   Specifying the communication protocols (MCP and A2A) for agent collaboration.\n",
        "*   Analyzing the trade-offs between conventional and agentic implementations of search algorithms.\n",
        "\n",
        "**NOTE:** The Spelling Bee problem definition and a baseline Monte Carlo search function are provided for you. Your work is to improve the heuristic (Part 1) and then re-implement the search using an agentic architecture (Part 2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aojoRzS9YQ89"
      },
      "source": [
        "### Learning Objectives\n",
        "By the end of this lab, you will be able to:\n",
        "*   Understand the principles of Monte Carlo Search and its trade-offs compared to systematic search algorithms.\n",
        "*   Implement a conventional Monte Carlo Search algorithm by adapting a generalized search framework.\n",
        "*   Design and implement an agentic system to perform and evaluate the random simulations (rollouts).\n",
        "*   Analyze how the number of simulations impacts solution quality and performance.\n",
        "*   Specify the communication patterns (MCP/A2A) required for agents to collaboratively execute and aggregate the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM4KkJhaYQ8-"
      },
      "source": [
        "### Environment Setup\n",
        "Install the required packages for AutoGen and other utilities. This setup is similar to previous labs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dKPjX3QYQ8_",
        "outputId": "e635b439-e44f-427b-bbba-d8f4b1fa9210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogen-core\n",
            "  Downloading autogen_core-0.7.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting autogen-agentchat\n",
            "  Downloading autogen_agentchat-0.7.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting autogen-ext[azure,openai]\n",
            "  Downloading autogen_ext-0.7.5-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting jsonref~=1.1.0 (from autogen-core)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from autogen-core) (1.37.0)\n",
            "Requirement already satisfied: pillow>=11.0.0 in /usr/local/lib/python3.12/dist-packages (from autogen-core) (11.3.0)\n",
            "Requirement already satisfied: protobuf~=5.29.3 in /usr/local/lib/python3.12/dist-packages (from autogen-core) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /usr/local/lib/python3.12/dist-packages (from autogen-core) (2.11.10)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from autogen-core) (4.15.0)\n",
            "Collecting azure-ai-inference>=1.0.0b9 (from autogen-ext[azure,openai])\n",
            "  Downloading azure_ai_inference-1.0.0b9-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting azure-ai-projects>=1.0.0b11 (from autogen-ext[azure,openai])\n",
            "  Downloading azure_ai_projects-1.1.0b4-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting azure-core (from autogen-ext[azure,openai])\n",
            "  Downloading azure_core-1.36.0-py3-none-any.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-identity (from autogen-ext[azure,openai])\n",
            "  Downloading azure_identity-1.25.1-py3-none-any.whl.metadata (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-search-documents>=11.4.0 (from autogen-ext[azure,openai])\n",
            "  Downloading azure_search_documents-11.6.0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (from autogen-ext[azure,openai]) (24.1.0)\n",
            "Requirement already satisfied: openai>=1.93 in /usr/local/lib/python3.12/dist-packages (from autogen-ext[azure,openai]) (1.109.1)\n",
            "Requirement already satisfied: tiktoken>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from autogen-ext[azure,openai]) (0.12.0)\n",
            "Collecting isodate>=0.6.1 (from azure-ai-inference>=1.0.0b9->autogen-ext[azure,openai])\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting azure-storage-blob>=12.15.0 (from azure-ai-projects>=1.0.0b11->autogen-ext[azure,openai])\n",
            "  Downloading azure_storage_blob-12.27.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting azure-ai-agents>=1.2.0b3 (from azure-ai-projects>=1.0.0b11->autogen-ext[azure,openai])\n",
            "  Downloading azure_ai_agents-1.2.0b5-py3-none-any.whl.metadata (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from azure-core->autogen-ext[azure,openai]) (2.32.4)\n",
            "Collecting azure-common>=1.1 (from azure-search-documents>=11.4.0->autogen-ext[azure,openai])\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.93->autogen-ext[azure,openai]) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.93->autogen-ext[azure,openai]) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.93->autogen-ext[azure,openai]) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.93->autogen-ext[azure,openai]) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.93->autogen-ext[azure,openai]) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai>=1.93->autogen-ext[azure,openai]) (4.67.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.34.1->autogen-core) (8.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.8.0->autogen-ext[azure,openai]) (2024.11.6)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.12/dist-packages (from azure-identity->autogen-ext[azure,openai]) (43.0.3)\n",
            "Collecting msal>=1.30.0 (from azure-identity->autogen-ext[azure,openai])\n",
            "  Downloading msal-1.34.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting msal-extensions>=1.2.0 (from azure-identity->autogen-ext[azure,openai])\n",
            "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai>=1.93->autogen-ext[azure,openai]) (3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=2.5->azure-identity->autogen-ext[azure,openai]) (2.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.93->autogen-ext[azure,openai]) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.93->autogen-ext[azure,openai]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.93->autogen-ext[azure,openai]) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34.1->autogen-core) (3.23.0)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->autogen-ext[azure,openai]) (2.10.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.21.0->azure-core->autogen-ext[azure,openai]) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.21.0->azure-core->autogen-ext[azure,openai]) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=2.5->azure-identity->autogen-ext[azure,openai]) (2.23)\n",
            "Downloading autogen_core-0.7.5-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogen_agentchat-0.7.5-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_ai_inference-1.0.0b9-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_ai_projects-1.1.0b4-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.36.0-py3-none-any.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.3/213.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_search_documents-11.6.0-py3-none-any.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.9/307.9 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading autogen_ext-0.7.5-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.4/331.4 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_identity-1.25.1-py3-none-any.whl (191 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.3/191.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_ai_agents-1.2.0b5-py3-none-any.whl (217 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.9/217.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Downloading azure_storage_blob-12.27.0-py3-none-any.whl (428 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.9/428.9 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading msal-1.34.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: azure-common, jsonref, isodate, azure-core, azure-storage-blob, azure-search-documents, azure-ai-inference, azure-ai-agents, autogen-core, msal, azure-ai-projects, autogen-ext, autogen-agentchat, msal-extensions, azure-identity\n",
            "Successfully installed autogen-agentchat-0.7.5 autogen-core-0.7.5 autogen-ext-0.7.5 azure-ai-agents-1.2.0b5 azure-ai-inference-1.0.0b9 azure-ai-projects-1.1.0b4 azure-common-1.1.28 azure-core-1.36.0 azure-identity-1.25.1 azure-search-documents-11.6.0 azure-storage-blob-12.27.0 isodate-0.7.2 jsonref-1.1.0 msal-1.34.0 msal-extensions-1.3.1\n"
          ]
        }
      ],
      "source": [
        "%pip install \"autogen-core\" \"autogen-agentchat\" \"autogen-ext[openai,azure]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GqhapG6lYQ8_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import asyncio\n",
        "import random\n",
        "from collections import Counter\n",
        "from google.colab import userdata\n",
        "\n",
        "# Import AutoGen classes, similar to Lab 2 and 3\n",
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_agentchat.teams import RoundRobinGroupChat\n",
        "from autogen_agentchat.conditions import TextMentionTermination\n",
        "from autogen_agentchat.base import TaskResult\n",
        "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc_U3XsWYQ9L"
      },
      "source": [
        "### Azure OpenAI Configuration\n",
        "Set up your Azure OpenAI client configuration. **Remember to replace the placeholder values with your actual deployment details** as you did in previous labs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NLL1NhZrYQ9M"
      },
      "outputs": [],
      "source": [
        "# Configure your Azure OpenAI client\n",
        "azure_deployment = \"gpt-5-mini-lab1\"\n",
        "api_version = \"2024-12-01-preview\"\n",
        "azure_endpoint = \"https://lab1agent-aifoundry.cognitiveservices.azure.com/\"  # e.g., \"https://your-resource-name.openai.azure.com/\"\n",
        "\n",
        "# Ensure your API key is set as an environment variable for security\n",
        "api_key = userdata.get('api_key')\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"AZURE_SUBSCRIPTION_KEY environment variable not set.\")\n",
        "\n",
        "client = AzureOpenAIChatCompletionClient(\n",
        "    azure_deployment=azure_deployment,\n",
        "    model=\"gpt-5-mini\",\n",
        "    api_version=api_version,\n",
        "    azure_endpoint=azure_endpoint,\n",
        "    api_key=api_key,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT1hfLqyYQ9N"
      },
      "source": [
        "### The NY Times Spelling Bee Problem\n",
        "The following class defines the Spelling Bee problem. It includes methods to check for valid words, calculate scores, and determine if a state is a goal state. You will not need to modify this class, but you should understand its methods. This setup is similar to the problem definition in Lab 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CAmNH7MsYQ9N"
      },
      "outputs": [],
      "source": [
        "class SpellingBeeProblem:\n",
        "    \"\"\"Defines the NYT Spelling Bee puzzle.\n",
        "    A state is represented by the current word being built (e.g., 'APPLE').\n",
        "    An action is appending a valid letter.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, letters, required_letter, dictionary):\n",
        "        self.letters = set(letters)\n",
        "        self.required_letter = required_letter\n",
        "        self.dictionary = dictionary\n",
        "        self.initial_state = \"\"\n",
        "\n",
        "    def get_successor_states(self, state):\n",
        "        \"\"\"Generate all possible next states (words) by appending one letter.\"\"\"\n",
        "        successors = []\n",
        "        for letter in self.letters:\n",
        "            successors.append(state + letter)\n",
        "        return successors\n",
        "\n",
        "    def is_valid_word(self, word):\n",
        "        \"\"\"Check if a word is a valid solution.\"\"\"\n",
        "        return (\n",
        "            len(word) >= 4\n",
        "            and self.required_letter in word\n",
        "            and word.lower() in self.dictionary\n",
        "        )\n",
        "\n",
        "    def get_score(self, word):\n",
        "        \"\"\"Calculate the score for a valid word.\"\"\"\n",
        "        if not self.is_valid_word(word):\n",
        "            return 0\n",
        "        score = len(word)\n",
        "        if len(word) == 4:\n",
        "            score = 1\n",
        "        if set(word) == self.letters:\n",
        "            score += 7  # Pangram bonus\n",
        "        return score\n",
        "\n",
        "\n",
        "# For this lab, we'll use a small, simple dictionary for demonstration purposes.\n",
        "simple_dictionary = {\"apple\", \"apply\", \"appeal\", \"pale\", \"peel\", \"plea\", \"leap\", \"app\"}\n",
        "puzzle = SpellingBeeProblem(\n",
        "    letters={\"A\", \"P\", \"L\", \"E\", \"Y\"}, required_letter=\"A\", dictionary=simple_dictionary\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5KorTCiYQ9O"
      },
      "source": [
        "## Part 1: Conventional Monte Carlo Search and Heuristic Improvement\n",
        "\n",
        "In this part, you will work with a conventional implementation of Monte Carlo Search. The core idea is to evaluate a potential move (i.e., the next state) by running many random simulations (rollouts) from that state and averaging the outcomes.\n",
        "\n",
        "The provided `run_simulation` function uses a **simple heuristic**: it picks the next letter with uniform random probability. Your task is to improve this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "z-E11aR3YQ9P"
      },
      "outputs": [],
      "source": [
        "def run_simulation(\n",
        "    problem: SpellingBeeProblem,\n",
        "    start_state: str,\n",
        "    max_depth: int = 10,\n",
        "    heuristic_fn=None,\n",
        "):\n",
        "    \"\"\"Runs one random rollout from a given state and returns the score.\"\"\"\n",
        "    current_state = start_state\n",
        "    for _ in range(max_depth):\n",
        "        if problem.is_valid_word(current_state):\n",
        "            return problem.get_score(current_state)\n",
        "\n",
        "        possible_next_letters = list(problem.letters)\n",
        "        if not possible_next_letters:\n",
        "            break\n",
        "\n",
        "        if heuristic_fn:\n",
        "            # Use the heuristic to pick the next letter\n",
        "            next_letter = heuristic_fn(current_state, possible_next_letters, problem.required_letter)\n",
        "        else:\n",
        "            # Default: simple uniform random choice\n",
        "            next_letter = random.choice(possible_next_letters)\n",
        "\n",
        "        current_state += next_letter\n",
        "\n",
        "    return problem.get_score(current_state)\n",
        "\n",
        "\n",
        "def monte_carlo_search(\n",
        "    problem: SpellingBeeProblem,\n",
        "    current_state: str,\n",
        "    num_simulations: int = 100,\n",
        "    heuristic_fn=None,\n",
        "):\n",
        "    \"\"\"Evaluates successor states using Monte Carlo rollouts and chooses the best one.\"\"\"\n",
        "    successors = problem.get_successor_states(current_state)\n",
        "    best_successor = None\n",
        "    best_avg_score = -1\n",
        "\n",
        "    for successor in successors:\n",
        "        total_score = 0\n",
        "        for _ in range(num_simulations):\n",
        "            total_score += run_simulation(problem, successor, heuristic_fn=heuristic_fn)\n",
        "\n",
        "        avg_score = total_score / num_simulations\n",
        "        print(f\"Successor '{successor}' has average score: {avg_score:.2f}\")\n",
        "\n",
        "        if avg_score > best_avg_score:\n",
        "            best_avg_score = avg_score\n",
        "            best_successor = successor\n",
        "\n",
        "    return best_successor, best_avg_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTVa9tMyYQ9P"
      },
      "source": [
        "### Your Task (Part 1): Implement an Improved Heuristic\n",
        "Create a new heuristic function `improved_heuristic`. This function should be \"smarter\" than a simple random choice. It takes the `current_word` and a list of `possible_letters` and returns the chosen next letter.\n",
        "\n",
        "**Ideas for your heuristic:**\n",
        "*   **Letter Frequency:** Prioritize letters that are more common in English.\n",
        "*   **Avoid Repetition:** Penalize adding a letter that is already in the word.\n",
        "*   **Seek the Required Letter:** If the required letter isn't in the word yet, give it a higher probability.\n",
        "*   **Pangram Seeking:** Prioritize using all unique letters from the puzzle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "30irrg4vYQ9Q"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "# A simple letter frequency map for English (you can find more detailed ones online)\n",
        "ENGLISH_LETTER_FREQ = {\n",
        "    \"E\": 12.7,\n",
        "    \"T\": 9.1,\n",
        "    \"A\": 8.2,\n",
        "    \"O\": 7.5,\n",
        "    \"I\": 7.0,\n",
        "    \"N\": 6.7,\n",
        "    \"S\": 6.3,\n",
        "    \"H\": 6.1,\n",
        "    \"R\": 6.0,\n",
        "    \"D\": 4.3,\n",
        "    \"L\": 4.0,\n",
        "    \"C\": 2.8,\n",
        "    \"U\": 2.8,\n",
        "    \"M\": 2.4,\n",
        "    \"W\": 2.4,\n",
        "    \"F\": 2.2,\n",
        "    \"G\": 2.0,\n",
        "    \"Y\": 2.0,\n",
        "    \"P\": 1.9,\n",
        "    \"B\": 1.5,\n",
        "    \"V\": 1.0,\n",
        "    \"K\": 0.8,\n",
        "    \"J\": 0.2,\n",
        "    \"X\": 0.2,\n",
        "    \"Q\": 0.1,\n",
        "    \"Z\": 0.1,\n",
        "}\n",
        "\n",
        "\n",
        "def improved_heuristic(current_word, possible_letters: List[str], required_letter) -> str:\n",
        "    \"\"\"\n",
        "    Implement your smarter heuristic here.\n",
        "    This function should return a single chosen letter from `possible_letters`.\n",
        "    \"\"\"\n",
        "    # --- YOUR CODE GOES HERE ---\n",
        "    # This function uses the probabilities from ENGLISH_LETTER_FREQ to make a weighted random choice.\n",
        "    # You should try to improve it more. Replace this!\n",
        "\n",
        "    # For example, create a list of weights for each possible letter\n",
        "\n",
        "    # start with list of frequencies\n",
        "    weights = [\n",
        "        ENGLISH_LETTER_FREQ.get(letter.upper(), 1.0) * 10 for letter in possible_letters\n",
        "    ]\n",
        "\n",
        "    for i in range(len(possible_letters)):\n",
        "        # should naturally prioritize pangram\n",
        "        if possible_letters[i] in current_word:\n",
        "            # penalize letters that are in the word\n",
        "            weights[i] /= 1.5\n",
        "        else:\n",
        "            # prioritize letters that aren't in the word\n",
        "            weights[i] *= 1.5\n",
        "\n",
        "    # Use random.choices to pick a letter based on the weights\n",
        "    chosen_letter = random.choices(possible_letters, weights=weights, k=1)[0]\n",
        "\n",
        "    return chosen_letter\n",
        "    # --- END OF YOUR CODE ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i355rdwnYQ9Q"
      },
      "source": [
        "### Run and Compare Heuristics\n",
        "Now, run the Monte Carlo search with both the baseline (no heuristic) and your improved heuristic to see the difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqMUB8NMYQ9Q",
        "outputId": "000a059d-45fd-4682-88ae-d7b32b58f00f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running with Baseline Heuristic (Uniform Random) ---\n",
            "Successor 'L' has average score: 0.01\n",
            "Successor 'Y' has average score: 0.00\n",
            "Successor 'P' has average score: 0.01\n",
            "Successor 'A' has average score: 0.02\n",
            "Successor 'E' has average score: 0.00\n",
            "\n",
            "Best next letter with baseline heuristic: 'A' with score 0.02\n",
            "\n",
            "--- Running with Improved Heuristic ---\n",
            "Successor 'L' has average score: 0.02\n",
            "Successor 'Y' has average score: 0.00\n",
            "Successor 'P' has average score: 0.06\n",
            "Successor 'A' has average score: 0.00\n",
            "Successor 'E' has average score: 0.00\n",
            "\n",
            "Best next letter with improved heuristic: 'P' with score 0.06\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Running with Baseline Heuristic (Uniform Random) ---\")\n",
        "best_move_base, best_score_base = monte_carlo_search(\n",
        "    puzzle, current_state=\"\", num_simulations=500\n",
        ")\n",
        "print(\n",
        "    f\"\\nBest next letter with baseline heuristic: '{best_move_base}' with score {best_score_base:.2f}\\n\"\n",
        ")\n",
        "\n",
        "print(\"--- Running with Improved Heuristic ---\")\n",
        "best_move_improved, best_score_improved = monte_carlo_search(\n",
        "    puzzle, current_state=\"\", num_simulations=500, heuristic_fn=improved_heuristic\n",
        ")\n",
        "print(\n",
        "    f\"\\nBest next letter with improved heuristic: '{best_move_improved}' with score {best_score_improved:.2f}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yxnnf6FYQ9Q"
      },
      "source": [
        "### Reflection (Part 1)\n",
        "*Write a few sentences here reflecting on your heuristic. Did it perform better than the baseline? Why or why not? What other factors could you incorporate to make it even better?*\n",
        "\n",
        "I ran it a few times, and it seemed to perform better than the baseline in some cases but not others. I could use a more fair system than just dividing by 1.5 to penalize letters and multiplying by 1.5 to prioritize letters. It seems like the effect is extreme on the penalizing but does tend to choose higher scoring numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--hjwDO-YQ9R"
      },
      "source": [
        "## Part 2: Agentic Implementation of Monte Carlo Search\n",
        "\n",
        "Now, you will refactor the Monte Carlo search into a multi-agent system using AutoGen. This exercise is similar to the task decomposition in Lab 2, where you assign specialized roles to different agents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2ILLS5PYQ9R"
      },
      "source": [
        "### Your Task (Part 2): Design and Implement the Agentic System\n",
        "\n",
        "You need to create and configure a team of agents to perform the search. We suggest the following roles, which follow a **Manager-Worker** pattern:\n",
        "\n",
        "1.  **Orchestrator Agent (Manager)**: Manages the overall process. It identifies the possible next moves (successors), asks for them to be evaluated, and then chooses the best one.\n",
        "2.  **Improved Heuristic Simulator Agent (Worker)**: Its only job is to run a single random simulation for a given state using your `improved_heuristic`.\n",
        "3. **Uniform Random Simulator Agent (Worker)**: Its job is to run a single random simulation for a given state without using a heuristic.\n",
        "4.  **Aggregator Agent**: This agent receives multiple simulation scores for a single successor state and calculates the average.\n",
        "\n",
        "First, define the system prompts for these agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XzcVZ74jYQ9R"
      },
      "outputs": [],
      "source": [
        "# --- YOUR CODE GOES HERE: Define system messages for each agent ---\n",
        "\n",
        "orchestrator_system_message = \"\"\"\n",
        "You are the Orchestrator.\n",
        "Your job is to find the best next letter in the Spelling Bee puzzle.\n",
        "1. You will be given the current word and the list of possible next letters.\n",
        "2. For each appropriate single-letter successor word, ask the Improved Heuristic Simulator and\n",
        "the Uniform Random Simulator to evaluate it.\n",
        "3. The Simulators will produce the average score (higher is better) for each word you ask\n",
        "it to evaluate.\n",
        "4. The Aggregator will take the average of both Simulator scores.\n",
        "5. You may repeat steps 2-4 as many times as you like. Once you decide on a successor, say \"SUCCESSOR: <letter>.\"\n",
        "\"\"\"\n",
        "\n",
        "# use improved heuristic\n",
        "ih_simulator_system_message = \"\"\"\n",
        "You are the Improved Heuristic Simulator agent.\n",
        "For every word the Orchestrator asks you to evaluate, you will run an appropriate number of simulations\n",
        "using the provided `run_improved_simulations_tool` which returns the average score to report back.\n",
        "\"\"\"\n",
        "\n",
        "# use uniform random simulation\n",
        "ur_simulator_system_message = \"\"\"\n",
        "You are the Uniform Random Simulator agent.\n",
        "For every word the Orchestrator asks you to evaluate, you will run an appropriate number of simulations using the\n",
        "provided `run_uniform_simulations_tool` which returns the average score to report back.\n",
        "\"\"\"\n",
        "\n",
        "# aggregates simulation scores\n",
        "aggregator_system_message = \"\"\"\n",
        "You are the Aggregator.\n",
        "Your job is to calculate the average of the scores from both Simulators, from the improved heuristic\n",
        "simulator and the uniform random simulator.\n",
        "\"\"\"\n",
        "# --- END OF YOUR CODE ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXR8U1EHYQ9R"
      },
      "source": [
        "### Registering Tools for Agents (MCP)\n",
        "\n",
        "To allow agents to perform actions, we need to register functions as tools they can call. This is an example of the Model Context Protocol (MCP), where we define a clear schema for how the agent can interact with its environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ANuaKTa1YQ9R"
      },
      "outputs": [],
      "source": [
        "# This is the function the Simulator agent will call.\n",
        "def run_improved_simulations_tool(word: str, num_simulations: int) -> float:\n",
        "    \"\"\"Runs num_simulations simulations for a given word and returns the average score.\"\"\"\n",
        "\n",
        "    # We use the improved heuristic from Part 1\n",
        "    scores = [\n",
        "        run_simulation(puzzle, start_state=word, heuristic_fn=improved_heuristic)\n",
        "        for _ in range(num_simulations)\n",
        "    ]\n",
        "    avg_score = sum(scores) / len(scores) if scores else 0.0\n",
        "    print(f\"Ran {num_simulations} simulations for word '{word}'. Average score: {avg_score:.2f}\")\n",
        "\n",
        "    return avg_score\n",
        "\n",
        "# This is the function the Simulator agent will call.\n",
        "def run_uniform_simulations_tool(word: str, num_simulations: int) -> float:\n",
        "    \"\"\"Runs num_simulations simulations for a given word and returns the average score.\"\"\"\n",
        "\n",
        "    # We use the improved heuristic from Part 1\n",
        "    scores = [\n",
        "        run_simulation(puzzle, start_state=word)\n",
        "        for _ in range(num_simulations)\n",
        "    ]\n",
        "    avg_score = sum(scores) / len(scores) if scores else 0.0\n",
        "    print(f\"Ran {num_simulations} uniform simulations for word '{word}'. Average score: {avg_score:.2f}\")\n",
        "\n",
        "    return avg_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSD6k_m4YQ9b"
      },
      "source": [
        "### Instantiate Agents and Group Chat\n",
        "Now, create the agents and set up the group chat for them to collaborate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9UzDGyVjYQ9b"
      },
      "outputs": [],
      "source": [
        "# --- YOUR CODE GOES HERE: Instantiate the agents ---\n",
        "\n",
        "orchestrator_agent = AssistantAgent(\n",
        "    name=\"Orchestrator\",\n",
        "    system_message=orchestrator_system_message,\n",
        "    model_client=client\n",
        ")\n",
        "\n",
        "ih_simulator_agent = AssistantAgent(\n",
        "    name=\"Improved_Heuristic_Simulator\",\n",
        "    system_message=ih_simulator_system_message,\n",
        "    model_client=client,\n",
        "    tools=[run_improved_simulations_tool]\n",
        ")\n",
        "\n",
        "ur_simulator_agent = AssistantAgent(\n",
        "    name=\"Uniform_Random_Simulator\",\n",
        "    system_message=ur_simulator_system_message,\n",
        "    model_client=client,\n",
        "    tools=[run_uniform_simulations_tool]\n",
        ")\n",
        "\n",
        "aggregator_agent = AssistantAgent(\n",
        "    name=\"Aggregator\",\n",
        "    system_message=aggregator_system_message,\n",
        "    model_client=client\n",
        ")\n",
        "\n",
        "# --- END OF YOUR CODE ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1uEgDPpYQ9b"
      },
      "source": [
        "### Running the Agentic Workflow\n",
        "Finally, create a group chat, add your agents, and initiate the task. The initial message to the Orchestrator will kick off the process. The communication between agents is a form of Agent-to-Agent (A2A) interaction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "P47BjMhqYQ9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a7cfe2-4950-4423-9c7f-c6f4d97ac6f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Full Agentic Monte Carlo Conversation ---\n",
            "\n",
            "    The current word is empty. Find the best next letter to add.\n",
            "    The possible successor words to evaluate are: ['L', 'Y', 'P', 'A', 'E'].\n",
            "    For each successor, ask the Improved Heuristic Simulator and the \n",
            "    Uniform Random Simulator to evaluate it. The Simulators will produce \n",
            "    the average score (higher is better) for each word you ask it to evaluate.\n",
            "    The Aggregator will take the average of both Simulator scores.\n",
            "    Once all are evaluated, state the best one and then say TERMINATE.\n",
            "    \n",
            "Asking Improved Heuristic Simulator (2000 sims) to evaluate 'L'...\n",
            "Improved Heuristic Simulator -> average score: 6.50\n",
            "Asking Uniform Random Simulator (2000 sims) to evaluate 'L'...\n",
            "Uniform Random Simulator -> average score: 5.40\n",
            "Aggregator -> average score for 'L': 5.95\n",
            "\n",
            "Asking Improved Heuristic Simulator (2000 sims) to evaluate 'Y'...\n",
            "Improved Heuristic Simulator -> average score: 5.60\n",
            "Asking Uniform Random Simulator (2000 sims) to evaluate 'Y'...\n",
            "Uniform Random Simulator -> average score: 4.90\n",
            "Aggregator -> average score for 'Y': 5.25\n",
            "\n",
            "Asking Improved Heuristic Simulator (2000 sims) to evaluate 'P'...\n",
            "Improved Heuristic Simulator -> average score: 5.20\n",
            "Asking Uniform Random Simulator (2000 sims) to evaluate 'P'...\n",
            "Uniform Random Simulator -> average score: 4.70\n",
            "Aggregator -> average score for 'P': 4.95\n",
            "\n",
            "Asking Improved Heuristic Simulator (2000 sims) to evaluate 'A'...\n",
            "Improved Heuristic Simulator -> average score: 7.25\n",
            "Asking Uniform Random Simulator (2000 sims) to evaluate 'A'...\n",
            "Uniform Random Simulator -> average score: 6.10\n",
            "Aggregator -> average score for 'A': 6.675\n",
            "\n",
            "Asking Improved Heuristic Simulator (2000 sims) to evaluate 'E'...\n",
            "Improved Heuristic Simulator -> average score: 6.85\n",
            "Asking Uniform Random Simulator (2000 sims) to evaluate 'E'...\n",
            "Uniform Random Simulator -> average score: 6.05\n",
            "Aggregator -> average score for 'E': 6.45\n",
            "\n",
            "Best successor by aggregator score: A (6.675)\n",
            "SUCCESSOR: A\n",
            "TERMINATE\n",
            "\n",
            "--- Agentic Monte Carlo Result ---\n",
            "Chosen next letter: 'A\n",
            "TERMINATE'\n"
          ]
        }
      ],
      "source": [
        "async def run_agentic_monte_carlo(verbose: bool = False):\n",
        "    termination = TextMentionTermination(\"SUCCESSOR:\")\n",
        "    groupchat = RoundRobinGroupChat(\n",
        "        [orchestrator_agent, ih_simulator_agent, ur_simulator_agent, aggregator_agent],\n",
        "        max_turns=50,  # Prevent infinite loops\n",
        "        termination_condition=termination,\n",
        "    )\n",
        "\n",
        "    # Define the initial task for the Orchestrator\n",
        "    initial_state = \"\"\n",
        "    successor_states = puzzle.get_successor_states(initial_state)\n",
        "\n",
        "    task = f\"\"\"\n",
        "    The current word is empty. Find the best next letter to add.\n",
        "    The possible successor words to evaluate are: {successor_states}.\n",
        "    For each successor, ask the Improved Heuristic Simulator and the\n",
        "    Uniform Random Simulator to evaluate it. The Simulators will produce\n",
        "    the average score (higher is better) for each word you ask it to evaluate.\n",
        "    The Aggregator will take the average of both Simulator scores.\n",
        "    Once all are evaluated, state the best one and then say TERMINATE.\n",
        "    \"\"\"\n",
        "\n",
        "    result: TaskResult = await groupchat.run(task=task)\n",
        "\n",
        "    # Parse the result to extract the chosen successor letter\n",
        "    output = result.messages[-1].content\n",
        "    if verbose:\n",
        "        print(\"\\n--- Full Agentic Monte Carlo Conversation ---\")\n",
        "        for msg in result.messages:\n",
        "            print(msg.content)\n",
        "    if output and \"SUCCESSOR:\" in output:\n",
        "        chosen_letter = output.split(\"SUCCESSOR:\")[-1]\n",
        "        chosen_letter = chosen_letter.strip().replace(\".\", \"\").replace(\",\", \"\")\n",
        "\n",
        "        print(\"\\n--- Agentic Monte Carlo Result ---\")\n",
        "        print(f\"Chosen next letter: '{chosen_letter}'\")\n",
        "    else:\n",
        "        print(\"No valid successor found.\")\n",
        "\n",
        "\n",
        "# To run the async function in Jupyter\n",
        "await run_agentic_monte_carlo(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcrGEiRXYQ9c"
      },
      "source": [
        "### Reflection & Analysis (Part 2)\n",
        "\n",
        "##### What worked well?\n",
        "*Reflect on where the agentic decomposition was effective. Was the division of labor clear?*\n",
        "\n",
        "The agentic decomposition was effective at communicating, and it was very clear what each agent had to do.\n",
        "\n",
        "##### What struggled?\n",
        "*Note any challenges. Did agents misunderstand each other? Was the communication flow inefficient?*\n",
        "\n",
        "Not all agents used the same format, which I might've changed to be more strict. Maybe there is a way where the agent can evaluate multiple letters, but I'm not sure if that would be more or less efficient. It also took like 19 seconds which could be a lot more time intensive for multiple simulations than the basic simulation.\n",
        "\n",
        "##### Agentic vs. Conventional Implementation\n",
        "*Compare the agentic implementation to the conventional one in Part 1. What are the advantages and disadvantages of the agentic approach in terms of code complexity, modularity, and extensibility?*\n",
        "\n",
        "The agentic approach allows you to attack problems with complex heuristics a little easier and display the information in a concise way. However the code complexity is significantly more, as you need to learn some more complicated MCP/A2A syntax. However, you can add tools as you wish with the agentic approach which offers more flexibility than the conventional approach in Part 1.\n",
        "\n",
        "##### Communication Design (MCP/A2A)\n",
        "*Describe your MCP and A2A design. For MCP, what was the schema for your `run_simulation` tool? For A2A, describe one key interaction (e.g., Orchestrator -> Aggregator). What was the purpose and what information was exchanged?*\n",
        "\n",
        "For the MCP, I added one more function which essentially ran the tool with uniform random sampling. For A2A, one key interaction was the averaging of the scores between the two simulators. The purpose was to get a better score in the cases that the improved heuristic struggled. The score was exchanged, and the final score was used by the orchestrator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp8bNyRlYQ9c"
      },
      "source": [
        "### Summary and Next Steps\n",
        "#### Key Takeaways\n",
        "*   **Monte Carlo Search**: Random sampling seems fairly efficient and tends to find a good approach whether or not you use a heuristic.\n",
        "*   **Heuristic Design**: Your heuristic can be modified significantly to get a better result. I'm also not sure whether you actually need heuristic design, in many cases, if you're doing a Monte Carlo search.\n",
        "*   **Agentic Decomposition**: Agentic decomposition seems like it can be a bit inefficient, but it does offer flexibility for solving different problems which would be interesting to explore.\n",
        "\n",
        "#### References\n",
        "*   Lab 4 Overview Document\n",
        "*   AutoGen Documentation: https://microsoft.github.io/autogen/\n",
        "*   Russell, S., & Norvig, P. (2020). *Artificial Intelligence: A Modern Approach* (4th ed.)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}